{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.stats import norm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>DemandID</th>\n",
       "      <th>Demand Request Date</th>\n",
       "      <th>Mix</th>\n",
       "      <th>jarSize</th>\n",
       "      <th>State</th>\n",
       "      <th>Quantity</th>\n",
       "      <th>Earliest Delivery Date</th>\n",
       "      <th>Preferred Delivery Date</th>\n",
       "      <th>Latest Delivery Date</th>\n",
       "      <th>Earliest Acceptable Shipping Date</th>\n",
       "      <th>Preferred Shipping Date</th>\n",
       "      <th>Latest Acceptable Shipping Date</th>\n",
       "      <th>MinOrderToShip</th>\n",
       "      <th>PrefOrderToShip</th>\n",
       "      <th>MaxOrderToShip</th>\n",
       "      <th>Smoothed Daily Demand</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Apple-Mango</td>\n",
       "      <td>8</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2021-01-04</td>\n",
       "      <td>2021-01-07</td>\n",
       "      <td>2020-12-27</td>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>-5</td>\n",
       "      <td>-2</td>\n",
       "      <td>1</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>39</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Orange-Passionfruit</td>\n",
       "      <td>32</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2021-01-03</td>\n",
       "      <td>2021-01-03</td>\n",
       "      <td>2020-12-27</td>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>-5</td>\n",
       "      <td>-3</td>\n",
       "      <td>-3</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>53</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>Grape-Pomegranate</td>\n",
       "      <td>8</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>2021-01-07</td>\n",
       "      <td>2021-01-18</td>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>2021-01-13</td>\n",
       "      <td>-4</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0.058824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>125</td>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>Cherry-Lime</td>\n",
       "      <td>32</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-03</td>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>2021-01-08</td>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>2021-01-03</td>\n",
       "      <td>-4</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>182</td>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>Strawberry-Kiwi</td>\n",
       "      <td>32</td>\n",
       "      <td>Maryland</td>\n",
       "      <td>1</td>\n",
       "      <td>2021-01-02</td>\n",
       "      <td>2021-01-03</td>\n",
       "      <td>2021-01-06</td>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>2021-01-01</td>\n",
       "      <td>-5</td>\n",
       "      <td>-4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0.200000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   DemandID Demand Request Date                  Mix  jarSize     State  \\\n",
       "0         1          2021-01-01          Apple-Mango        8  Maryland   \n",
       "1        39          2021-01-01  Orange-Passionfruit       32  Maryland   \n",
       "2        53          2021-01-01    Grape-Pomegranate        8  Maryland   \n",
       "3       125          2021-01-02          Cherry-Lime       32  Maryland   \n",
       "4       182          2021-01-02      Strawberry-Kiwi       32  Maryland   \n",
       "\n",
       "   Quantity Earliest Delivery Date Preferred Delivery Date  \\\n",
       "0         1             2021-01-01              2021-01-04   \n",
       "1         1             2021-01-01              2021-01-03   \n",
       "2         1             2021-01-02              2021-01-07   \n",
       "3         1             2021-01-03              2021-01-06   \n",
       "4         1             2021-01-02              2021-01-03   \n",
       "\n",
       "  Latest Delivery Date Earliest Acceptable Shipping Date  \\\n",
       "0           2021-01-07                        2020-12-27   \n",
       "1           2021-01-03                        2020-12-27   \n",
       "2           2021-01-18                        2020-12-28   \n",
       "3           2021-01-08                        2020-12-29   \n",
       "4           2021-01-06                        2020-12-28   \n",
       "\n",
       "  Preferred Shipping Date Latest Acceptable Shipping Date  MinOrderToShip  \\\n",
       "0              2020-12-30                      2021-01-02              -5   \n",
       "1              2020-12-29                      2020-12-29              -5   \n",
       "2              2021-01-02                      2021-01-13              -4   \n",
       "3              2021-01-01                      2021-01-03              -4   \n",
       "4              2020-12-29                      2021-01-01              -5   \n",
       "\n",
       "   PrefOrderToShip  MaxOrderToShip  Smoothed Daily Demand  \n",
       "0               -2               1               0.142857  \n",
       "1               -3              -3               0.333333  \n",
       "2                1              12               0.058824  \n",
       "3               -1               1               0.166667  \n",
       "4               -4              -1               0.200000  "
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read modified_data/\n",
    "df_demand_log = pd.read_csv('modified_data/df_demand_log_t5.csv')\n",
    "df_demand_log.rename(columns={'Jar Size  (vol. ounces)': 'jarSize'}, inplace=True)\n",
    "df_demand_log.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentage of lost demand: 25.21%\n"
     ]
    }
   ],
   "source": [
    "# Query where orders are impossible to fulfill\n",
    "lost_demand = df_demand_log.query('MaxOrderToShip < 0')\n",
    "acheivable_demand = df_demand_log.query('MaxOrderToShip >= 0')\n",
    "\n",
    "# Percentage of lost demand\n",
    "lost_demand_percentage = lost_demand['Quantity'].sum() / df_demand_log['Quantity'].sum() * 100\n",
    "\n",
    "print(f'Percentage of lost demand: {lost_demand_percentage:.2f}%')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "About 25% of the volume of demand is lost due shipping timelines where the mix that was order would have to be shipped date before the day of request, or earlier. Depending on the responsiveness of the supply chain, this could potentially make day of shipping or shortly after impossible as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "production_capacity = pd.read_excel('FruitSoul Production and Materials Characteristics and Costs.xlsx', sheet_name='Center Capacity', header=2)\n",
    "production_capacity.rename(columns={'Unnamed: 1': 'Center', 'Unnamed: 7': \"Unit\"}, inplace=True)\n",
    "production_capacity.drop(columns=['Unnamed: 0'], inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mixing Demand History\n",
    "\n",
    "Because mixing demand is measured in ounces, it's demand is not exactly in line with packaging and bottling demand."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demand History: Ounces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/1g/8vbqswf55db7cq6z4fs9npbr0000gn/T/ipykernel_30384/2866100714.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  acheivable_demand['ozOfProduct'] = acheivable_demand['Quantity'] * acheivable_demand['jarSize']\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[284], line 56\u001b[0m\n\u001b[1;32m     53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m df_demand_distribution[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMix\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msmoothedDailyDemand\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Apply the function to each row in the demand log and concatenate the results\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m smoothed_ounces_demand \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([\u001b[43mdemand_probability\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrow\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol_name\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mozOfProduct\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m acheivable_demand\u001b[38;5;241m.\u001b[39miterrows()])\n",
      "Cell \u001b[0;32mIn[284], line 51\u001b[0m, in \u001b[0;36mdemand_probability\u001b[0;34m(row, col_name)\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pd\u001b[38;5;241m.\u001b[39mDataFrame(columns\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMix\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSmoothed Daily Demand\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m     50\u001b[0m \u001b[38;5;66;03m# Normalize probabilities to sum up to 1, then scale to match total quantity\u001b[39;00m\n\u001b[0;32m---> 51\u001b[0m df_demand_distribution[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msmoothedDailyDemand\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43m(\u001b[49m\u001b[43mdf_demand_distribution\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mProbability\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[43mcol_name\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     53\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df_demand_distribution[[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMix\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msmoothedDailyDemand\u001b[39m\u001b[38;5;124m'\u001b[39m]]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/data-science/lib/python3.12/site-packages/pandas/core/ops/common.py:76\u001b[0m, in \u001b[0;36m_unpack_zerodim_and_defer.<locals>.new_method\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mNotImplemented\u001b[39m\n\u001b[1;32m     74\u001b[0m other \u001b[38;5;241m=\u001b[39m item_from_zerodim(other)\n\u001b[0;32m---> 76\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/data-science/lib/python3.12/site-packages/pandas/core/arraylike.py:202\u001b[0m, in \u001b[0;36mOpsMixin.__mul__\u001b[0;34m(self, other)\u001b[0m\n\u001b[1;32m    200\u001b[0m \u001b[38;5;129m@unpack_zerodim_and_defer\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__mul__\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    201\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__mul__\u001b[39m(\u001b[38;5;28mself\u001b[39m, other):\n\u001b[0;32m--> 202\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moperator\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/data-science/lib/python3.12/site-packages/pandas/core/series.py:5819\u001b[0m, in \u001b[0;36mSeries._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   5817\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_arith_method\u001b[39m(\u001b[38;5;28mself\u001b[39m, other, op):\n\u001b[1;32m   5818\u001b[0m     \u001b[38;5;28mself\u001b[39m, other \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_align_for_op(other)\n\u001b[0;32m-> 5819\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mbase\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mIndexOpsMixin\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_arith_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mother\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mop\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/data-science/lib/python3.12/site-packages/pandas/core/base.py:1383\u001b[0m, in \u001b[0;36mIndexOpsMixin._arith_method\u001b[0;34m(self, other, op)\u001b[0m\n\u001b[1;32m   1380\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m np\u001b[38;5;241m.\u001b[39merrstate(\u001b[38;5;28mall\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m   1381\u001b[0m     result \u001b[38;5;241m=\u001b[39m ops\u001b[38;5;241m.\u001b[39marithmetic_op(lvalues, rvalues, op)\n\u001b[0;32m-> 1383\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_construct_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mres_name\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/data-science/lib/python3.12/site-packages/pandas/core/series.py:5915\u001b[0m, in \u001b[0;36mSeries._construct_result\u001b[0;34m(self, result, name)\u001b[0m\n\u001b[1;32m   5912\u001b[0m \u001b[38;5;66;03m# TODO: result should always be ArrayLike, but this fails for some\u001b[39;00m\n\u001b[1;32m   5913\u001b[0m \u001b[38;5;66;03m#  JSONArray tests\u001b[39;00m\n\u001b[1;32m   5914\u001b[0m dtype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(result, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[0;32m-> 5915\u001b[0m out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_constructor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m   5916\u001b[0m out \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39m__finalize__(\u001b[38;5;28mself\u001b[39m)\n\u001b[1;32m   5918\u001b[0m \u001b[38;5;66;03m# Set the result's name after __finalize__ is called because __finalize__\u001b[39;00m\n\u001b[1;32m   5919\u001b[0m \u001b[38;5;66;03m#  would set it back to self.name\u001b[39;00m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/data-science/lib/python3.12/site-packages/pandas/core/series.py:514\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[0;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[1;32m    511\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    512\u001b[0m     data \u001b[38;5;241m=\u001b[39m sanitize_array(data, index, dtype, copy)\n\u001b[0;32m--> 514\u001b[0m     manager \u001b[38;5;241m=\u001b[39m \u001b[43mget_option\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmode.data_manager\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    515\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    516\u001b[0m         data \u001b[38;5;241m=\u001b[39m SingleBlockManager\u001b[38;5;241m.\u001b[39mfrom_array(data, index, refs\u001b[38;5;241m=\u001b[39mrefs)\n",
      "File \u001b[0;32m/opt/anaconda3/envs/data-science/lib/python3.12/site-packages/pandas/_config/config.py:272\u001b[0m, in \u001b[0;36mCallableDynamicDoc.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    271\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[0;32m--> 272\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__func__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/anaconda3/envs/data-science/lib/python3.12/site-packages/pandas/_config/config.py:149\u001b[0m, in \u001b[0;36m_get_option\u001b[0;34m(pat, silent)\u001b[0m\n\u001b[1;32m    146\u001b[0m key \u001b[38;5;241m=\u001b[39m _get_single_key(pat, silent)\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m# walk the nested dict\u001b[39;00m\n\u001b[0;32m--> 149\u001b[0m root, k \u001b[38;5;241m=\u001b[39m \u001b[43m_get_root\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m root[k]\n",
      "File \u001b[0;32m/opt/anaconda3/envs/data-science/lib/python3.12/site-packages/pandas/_config/config.py:633\u001b[0m, in \u001b[0;36m_get_root\u001b[0;34m(key)\u001b[0m\n\u001b[1;32m    628\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m keys\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [k \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m keys \u001b[38;5;28;01mif\u001b[39;00m re\u001b[38;5;241m.\u001b[39msearch(pat, k, re\u001b[38;5;241m.\u001b[39mI)]\n\u001b[0;32m--> 633\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_root\u001b[39m(key: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[\u001b[38;5;28mdict\u001b[39m[\u001b[38;5;28mstr\u001b[39m, Any], \u001b[38;5;28mstr\u001b[39m]:\n\u001b[1;32m    634\u001b[0m     path \u001b[38;5;241m=\u001b[39m key\u001b[38;5;241m.\u001b[39msplit(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    635\u001b[0m     cursor \u001b[38;5;241m=\u001b[39m _global_config\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Create total ounces columns\n",
    "acheivable_demand['ozOfProduct'] = acheivable_demand['Quantity'] * acheivable_demand['jarSize']\n",
    "\n",
    "# Preferred Demand History\n",
    "preferred_ounces_demand = acheivable_demand.groupby([\"Preferred Shipping Date\"]).agg({\"ozOfProduct\": \"sum\"}).reset_index().rename(columns={\"jarSize\": \"Ounces Demand\"})\n",
    "\n",
    "# Earliest Arrival Demand History\n",
    "early_ounces_demand = acheivable_demand.groupby([\"Earliest Acceptable Shipping Date\"]).agg({\"ozOfProduct\": \"sum\"}).reset_index().rename(columns={\"jarSize\": \"Ounces Demand\"})\n",
    "\n",
    "# Latest Arrival Demand History\n",
    "late_ounces_demand = acheivable_demand.groupby([\"Latest Acceptable Shipping Date\"]).agg({\"ozOfProduct\": \"sum\"}).reset_index().rename(columns={\"jarSize\": \"Ounces Demand\"})\n",
    "\n",
    "# Smoothed Arrival Demand History\n",
    "\n",
    "def demand_probability(row, col_name='Quantity'):\n",
    "    preferred_date = pd.to_datetime(row['Preferred Shipping Date'])\n",
    "    earliest_date = pd.to_datetime(row['Earliest Acceptable Shipping Date'])\n",
    "    latest_date = pd.to_datetime(row['Latest Acceptable Shipping Date'])\n",
    "    \n",
    "    # Calculate the standard deviation (earliest/latest represent ±2 standard deviations)\n",
    "    std_dev = (latest_date - earliest_date).days / 4\n",
    "    \n",
    "    # Ensure std_dev is at least 1 to avoid division by zero\n",
    "    std_dev = max(std_dev, 1)\n",
    "    \n",
    "    # Initialize empty list for smoothed demand distribution\n",
    "    demand_distribution = []\n",
    "    \n",
    "    # Compute cumulative probabilities for the range of acceptable shipping dates\n",
    "    for day in pd.date_range(earliest_date, latest_date):\n",
    "        # CDF at the start and end of the day\n",
    "        cdf_start = norm.cdf((day - pd.Timedelta(days=0.5) - preferred_date).days, scale=std_dev)\n",
    "        cdf_end = norm.cdf((day + pd.Timedelta(days=0.5) - preferred_date).days, scale=std_dev)\n",
    "        \n",
    "        # Cumulative probability for the 24-hour period (between start and end of the day)\n",
    "        daily_probability = cdf_end - cdf_start\n",
    "        \n",
    "        demand_distribution.append({\n",
    "            'Date': day,\n",
    "            'Mix': row['Mix'],\n",
    "            'Probability': daily_probability\n",
    "        })\n",
    "    \n",
    "    # Convert list to DataFrame\n",
    "    df_demand_distribution = pd.DataFrame(demand_distribution)\n",
    "\n",
    "    if len(df_demand_distribution) == 0:\n",
    "        return pd.DataFrame(columns=['Date', 'Mix', 'Smoothed Daily Demand'])\n",
    "    \n",
    "    # Normalize probabilities to sum up to 1, then scale to match total quantity\n",
    "    df_demand_distribution['smoothedDailyDemand'] = (df_demand_distribution['Probability']) * row[col_name]\n",
    "    \n",
    "    return df_demand_distribution[['Date', 'Mix', 'smoothedDailyDemand']]\n",
    "\n",
    "# Apply the function to each row in the demand log and concatenate the results\n",
    "smoothed_ounces_demand = pd.concat([demand_probability(row, col_name = 'ozOfProduct') for _, row in acheivable_demand.iterrows()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demand History: Jars\n",
    "\n",
    "Because packaging and bottling demand is measured in jar, the demand will be identical for each order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preferred Demand History\n",
    "preferred_jars_demand = acheivable_demand.groupby([\"Preferred Shipping Date\"]).agg({\"Quantity\": \"sum\"}).reset_index().rename(columns={\"jarSize\": \"Jars Demand\"})\n",
    "# Earliest Arrival Demand History\n",
    "early_jars_demand = acheivable_demand.groupby([\"Earliest Acceptable Shipping Date\"]).agg({\"Quantity\": \"sum\"}).reset_index().rename(columns={\"jarSize\": \"Jars Demand\"})\n",
    "# Latest Arrival Demand History\n",
    "late_jars_demand = acheivable_demand.groupby([\"Latest Acceptable Shipping Date\"]).agg({\"Quantity\": \"sum\"}).reset_index().rename(columns={\"jarSize\": \"Jars Demand\"})\n",
    "\n",
    "# Smoothed Arrival Demand History\n",
    "smoothed_jars_demand = pd.concat([demand_probability(row, col_name = 'Quantity') for _, row in acheivable_demand.iterrows()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Adjust demand dates for off days\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to check if a date is Labor Day\n",
    "def is_labor_day(date):\n",
    "    if date.strftime('%m') == '09' and date.strftime('%d') <= '07' and date.weekday() == 0:\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "# Define the date for the 4th of July \n",
    "july_4th = '07-04'\n",
    "\n",
    "# Function to adjust dates for earliest or latest shipping dates on Sundays, labor days, or 4th of July\n",
    "def adjust_date(date, type='e'):\n",
    "    \"\"\"\n",
    "    Adjust the date based on the type:\n",
    "    'e' for Earliest Acceptable Shipping Date,\n",
    "    'l' for Latest Acceptable Shipping Date\n",
    "    \"\"\"\n",
    "    if type == 'e':\n",
    "        if date.weekday() == 6:\n",
    "            date = date + pd.Timedelta(days=1)\n",
    "        if is_labor_day(date) or date.strftime('%m-%d') == july_4th:\n",
    "            date = date + pd.Timedelta(days=1)\n",
    "            if date.weekday() == 6:\n",
    "                date = date + pd.Timedelta(days=1)\n",
    "        return date\n",
    "    \n",
    "    if type == 'l':\n",
    "        if is_labor_day(date) or date.strftime('%m-%d') == july_4th:\n",
    "            date = date - pd.Timedelta(days=1)\n",
    "        if date.weekday() == 6:\n",
    "            date = date - pd.Timedelta(days=1)\n",
    "            if is_labor_day(date) or date.strftime('%m-%d') == july_4th:\n",
    "                date = date - pd.Timedelta(days=1)\n",
    "        return date\n",
    "\n",
    "    return date\n",
    "\n",
    "# Adjust the dates\n",
    "smoothed_jars_demand['Date'] = smoothed_jars_demand['Date'].apply(lambda x: adjust_date(x, 'e'))\n",
    "smoothed_ounces_demand['Date'] = smoothed_ounces_demand['Date'].apply(lambda x: adjust_date(x, 'e'))\n",
    "\n",
    "# Function to check if a date is a Sunday, Labor Day, or the 4th of July\n",
    "def is_special_day(date):\n",
    "    return date.weekday() == 6 or is_labor_day(date) or date.strftime('%m-%d') == july_4th\n",
    "\n",
    "# Function to move the date forward by one day if it is a special day\n",
    "def adjust_preferred_shipping_date(date):\n",
    "    if is_special_day(date):\n",
    "        date += pd.Timedelta(days=1)\n",
    "        if is_special_day(date):\n",
    "            date -= pd.Timedelta(days=2)\n",
    "    return date\n",
    "\n",
    "# Apply the function to the Preferred Shipping Date column\n",
    "smoothed_jars_demand['Date'] = smoothed_jars_demand['Date'].apply(adjust_preferred_shipping_date)\n",
    "smoothed_ounces_demand['Date'] = smoothed_ounces_demand['Date'].apply(adjust_preferred_shipping_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "smoothed_jars_demand_date = smoothed_jars_demand.groupby('Date').agg({'smoothedDailyDemand': 'sum'}).reset_index()\n",
    "smoothed_ounces_demand_date = smoothed_ounces_demand.groupby('Date').agg({'smoothedDailyDemand': 'sum'}).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify production capacity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_production_demand(demand_vector, s = 5):\n",
    "    s_pctile_demand  = np.percentile(np.array(demand_vector), 100-s)\n",
    "    return s_pctile_demand\n",
    "\n",
    "def identify_max_daily_production(production_capacity, center_name = \"Mixing\"):\n",
    "    max_shift_production = production_capacity[production_capacity['Center'] == center_name][5].values[0]\n",
    "    max_daily_production = max_shift_production * 2\n",
    "    return max_daily_production\n",
    "\n",
    "def identify_cells_needed(demand, max_daily_production):\n",
    "    cells_needed = np.ceil(demand / max_daily_production)\n",
    "    return cells_needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "jars = smoothed_jars_demand_date.rename(columns={'smoothedDailyDemand': 'jarsDemand'})\n",
    "ounces = smoothed_ounces_demand_date.rename(columns={'smoothedDailyDemand': 'ouncesDemand'})\n",
    "\n",
    "# Merge on Date\n",
    "production_demand = jars.merge(ounces, on='Date', how='left')\n",
    "\n",
    "# Fill NA values with 0\\\n",
    "production_demand.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identify total cells needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_total_cells_needed(production_demand, production_capacity, center_name, s):\n",
    "    unit = production_capacity[production_capacity['Center'] == center_name]['Unit'].values[0]\n",
    "\n",
    "    if unit == \"Jars\":\n",
    "        demand_vector = production_demand['jarsDemand']\n",
    "    else:\n",
    "        demand_vector = production_demand['ouncesDemand']\n",
    "\n",
    "    s_pctile_demand = identify_production_demand(demand_vector, s)\n",
    "    max_daily_production = identify_max_daily_production(production_capacity, center_name)\n",
    "    cells_needed = identify_cells_needed(s_pctile_demand, max_daily_production)\n",
    "    return cells_needed"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optimize Daily Set-Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function to return demand for a given date\n",
    "def get_demand(date, production_demand, demandColumnName = 'jarsDemand'):\n",
    "    return production_demand[(production_demand['Date'] == date)][demandColumnName].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample date from production_demand['Date']\n",
    "random_date = production_demand['Date'].sample().values[0]\n",
    "\n",
    "# Get demand for the random date\n",
    "date_demand = get_demand(random_date, production_demand, 'ouncesDemand')\n",
    "\n",
    "# Identify active cells needed to account for all demand\n",
    "def active_cells(date, production_capacity, production_demand, centerName):\n",
    "    if centerName == 'Mixing':\n",
    "        demandType = 'ouncesDemand'\n",
    "    else:\n",
    "        demandType = 'jarsDemand'\n",
    "\n",
    "    date_demand = get_demand(date, production_demand, demandType)\n",
    "\n",
    "    active_cells_needed  = np.ceil(date_demand / identify_max_daily_production(production_capacity, centerName))\n",
    "\n",
    "    remaining_demand = date_demand - ((active_cells_needed  - 1) * identify_max_daily_production(production_capacity, centerName))\n",
    "\n",
    "    # Find workers needed function\n",
    "    def workers_needed(demand, production_capacity, centerName):\n",
    "        new_demand = demand/2 # 2 shifts\n",
    "        filtered_production_cap = production_capacity[production_capacity['Center'] == centerName]\n",
    "        # Drop first and last columns\n",
    "        filtered_production_cap = filtered_production_cap.drop(columns=['Center', 'Unit'])\n",
    "        # Find first row with capacity greater than demand, iterating through columns. If true, return column name\n",
    "        for col in filtered_production_cap.columns[1:]:\n",
    "            if new_demand <= filtered_production_cap[col].values[0]:\n",
    "                return col\n",
    "            \n",
    "    additional_workers = workers_needed(remaining_demand, production_capacity, centerName)\n",
    "\n",
    "    return active_cells_needed, additional_workers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_cells_over_time(production_demand, production_capacity, s, centerNames=[\"Mixing\", \"Bottling\", \"Packing\"]):\n",
    "    cells_needed_df = pd.DataFrame()  # Create an empty DataFrame to store the results\n",
    "    \n",
    "    for centerName in centerNames:\n",
    "        cells_needed = [] \n",
    "        \n",
    "        distinct_years = production_demand['Date'].dt.year.unique()\n",
    "        for year in distinct_years:\n",
    "            year_demand = production_demand[production_demand['Date'].dt.year == year]\n",
    "            cells_needed.append(identify_total_cells_needed(year_demand, production_capacity, centerName, s))\n",
    "        \n",
    "        center_df = pd.DataFrame({centerName: cells_needed})\n",
    "        cells_needed_df = pd.concat([cells_needed_df, center_df], axis=1)\n",
    "\n",
    "    cells_needed_df.insert(0, \"Year\", distinct_years)\n",
    "        \n",
    "    return cells_needed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_active_cells_plan(production_capacity, production_demand):\n",
    "    active_cells_df = pd.DataFrame()\n",
    "    date_range = production_demand['Date'].unique()\n",
    "\n",
    "    for date in date_range:\n",
    "        for cell in ['Mixing', 'Bottling', 'Packing']:\n",
    "            cells_needed, workers_in_last_cell = active_cells(date, production_capacity, production_demand, cell)\n",
    "            if cell == 'Mixing':\n",
    "                demand = get_demand(date, production_demand, 'ouncesDemand')\n",
    "            else:\n",
    "                demand = get_demand(date, production_demand, 'jarsDemand')\n",
    "            temp_df = pd.DataFrame({'Date': [date], 'centerName': [cell], 'cellsNeeded': [cells_needed], 'workersInLastCell': [workers_in_last_cell], 'demand': [demand]})\n",
    "            active_cells_df = pd.concat([active_cells_df, temp_df])\n",
    "    \n",
    "    return active_cells_df\n",
    "\n",
    "active_cells_df = create_active_cells_plan(production_capacity, production_demand)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_daily_table(production_capacity, production_demand, s):    \n",
    "    x = find_cells_over_time(production_demand, production_capacity, s)\n",
    "\n",
    "    y = create_active_cells_plan(production_capacity, production_demand)\n",
    "\n",
    "    # Create 'Year' column from 'Date'\n",
    "    y['Year'] = y['Date'].dt.year\n",
    "\n",
    "    # Pivot x longer based on ['Mixing', 'Bottling', 'Packing']\n",
    "    x_long = x.melt(id_vars=['Year'], var_name='Center', value_name='totalCells')\n",
    "\n",
    "    # Merge y with x_long \n",
    "    z = y.merge(x_long, left_on=['Year', 'centerName'], right_on=['Year', 'Center'], how = 'left')\n",
    "\n",
    "    z.drop(columns=['centerName', 'Year'], inplace=True)\n",
    "\n",
    "    z['totalCells'] = np.where(z['totalCells'] > z['cellsNeeded'], z['totalCells'], z['cellsNeeded'])\n",
    "\n",
    "    return z.drop(columns=['totalCells'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "production_costs = pd.read_excel('FruitSoul Production and Materials Characteristics and Costs.xlsx', sheet_name='Production Costs', header=2)\n",
    "production_costs.drop(columns=['Unnamed: 0'], inplace=True)\n",
    "production_costs.rename(columns={'Unnamed: 1': 'Center', 'Unnamed: 2': 'Set-Up Costs', 'Unnamed: 3': 'Operating Daily Costs'}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_setup_costs(yearly_cell_df):\n",
    "    setup_cost = yearly_cell_df.copy()\n",
    "    setup_cost_dict = {'Mixing': 15000, 'Bottling': 8000, 'Packing': 5000}\n",
    "\n",
    "    setup_cost['Mixing'] = setup_cost['Mixing'] * setup_cost_dict['Mixing']\n",
    "    setup_cost['Bottling'] = setup_cost['Bottling'] * setup_cost_dict['Bottling']\n",
    "    setup_cost['Packing'] = setup_cost['Packing'] * setup_cost_dict['Packing']\n",
    "\n",
    "    # Pivot longer to 2 columns [\"Date\", \"Cost Description\", \"Cost\"] from one for each \"Mixing\", \"Bottling\", \"Packing\" and \"Year\"\n",
    "    setup_cost.rename(columns={'Year': 'Date'}, inplace=True)\n",
    "    setup_cost_long = setup_cost.melt(id_vars=['Date'], var_name='Cost Description', value_name='Cost')\n",
    "\n",
    "    # Add \"Set-Up Costs\" to \"Cost Description\"\n",
    "    setup_cost_long['Cost Description'] = setup_cost_long['Cost Description'] + ' Set-Up Costs'\n",
    "\n",
    "    # Sort the DataFrame by 'Cost Description' and 'Date' to ensure proper grouping\n",
    "    setup_cost_long = setup_cost_long.sort_values(by=['Cost Description', 'Date'])\n",
    "\n",
    "    # Group by 'Cost Description' and calculate the difference (additional spending)\n",
    "    setup_cost_long['Additional Cost'] = setup_cost_long.groupby('Cost Description')['Cost'].diff().fillna(setup_cost_long['Cost'])\n",
    "    \n",
    "    setup_cost_long['Cost'] = setup_cost_long['Additional Cost']\n",
    "    setup_cost_long['Cumulative Cost'] = setup_cost_long.groupby('Cost Description')['Cost'].cumsum()\n",
    "\n",
    "    return setup_cost_long"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_cell_operating_costs(active_cells_df):\n",
    "    operating_cost = active_cells_df.copy()\n",
    "    operating_cost_dict = {'Mixing': 400, 'Bottling': 350, 'Packing': 600}\n",
    "\n",
    "    # Apply a function to each row to calculate the cost\n",
    "    def calculate_cost(row):\n",
    "        return row['cellsNeeded'] * operating_cost_dict[row['Center']]\n",
    "    \n",
    "    operating_cost['Cost'] = active_cells_df.apply(calculate_cost, axis=1)\n",
    "\n",
    "    # Rename the existing 'Cost' column temporarily to avoid conflict during melt\n",
    "    operating_cost.rename(columns={'Cost': 'dailyCost'}, inplace=True)\n",
    "\n",
    "    # Pivot longer Center column where values are the \"Cost\"\n",
    "    operating_cost_long = operating_cost.melt(id_vars=['Date', 'Center'], value_vars=['dailyCost'], var_name='Cost Description', value_name='Cost')\n",
    "\n",
    "    # Add \"Operating Daily Costs\" to \"Cost Description\"\n",
    "    operating_cost_long['Cost Description'] = operating_cost_long['Center'] + ' Cell Daily Costs'\n",
    "\n",
    "    # Group by \"Date\" (parse the year) and \"Cost Description\" and sum the \"Cost\"\n",
    "    yearly_data = operating_cost_long.copy()\n",
    "    yearly_data['Date'] = pd.to_datetime(yearly_data['Date'])\n",
    "    yearly_data['Date'] = yearly_data['Date'].dt.year\n",
    "\n",
    "    yearly_summary = yearly_data.groupby(['Date', 'Cost Description']).agg({'Cost': 'sum'}).reset_index()\n",
    "\n",
    "    return operating_cost_long[['Date', 'Cost Description', 'Cost']], yearly_summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_labor_costs(active_cells_df):\n",
    "    labor_cost = active_cells_df.copy()\n",
    "    labor_cost.rename(columns={'date': 'Date'}, inplace=True)\n",
    "    labor_cost['totalWorkers'] = 2 * (((labor_cost['cellsNeeded'] - 1) * 5) + labor_cost['workersInLastCell']) # 2 shifts\n",
    "    # We will operate so that on days where we are fully staffed in packaging, 80% of the workers are full-time\n",
    "    # First identify the maximum workers needed in Packing, this will still ensure the total workforce is at least 70% full time\n",
    "    max_packing_workers = labor_cost[labor_cost['Center'] == 'Packing']['totalWorkers'].max()\n",
    "    full_time_packing_workers = np.ceil(0.7 * max_packing_workers)\n",
    "    labor_cost['fullTimeWorkers'] = np.where(labor_cost['Center'].isin(['Mixing', 'Bottling']), labor_cost['totalWorkers'], full_time_packing_workers)\n",
    "    # If the number of totalWorkers is less than or equal to the # of full-time workers, we will have all workers as full-time\n",
    "    labor_cost['fullTimeWorkers'] = np.where(labor_cost['totalWorkers'] <= full_time_packing_workers, labor_cost['totalWorkers'], labor_cost['fullTimeWorkers'])\n",
    "    \n",
    "    labor_cost['partTimeWorkers'] = labor_cost['totalWorkers'] - labor_cost['fullTimeWorkers']\n",
    "\n",
    "    # Using heuristic that each worker will only work where they specialize, with no overtime\n",
    "    labor_cost_dict = {'Mixing': 20, 'Bottling': 15, 'Packing': 25}\n",
    "\n",
    "    # Apply a function to each row to calculate the cost, part-time workers are 1.15x more expensive than full-time workers\n",
    "    # Not necessarily the wages, but including costs of lost production, training, etc for part-time workers\n",
    "    def calculate_cost(row):\n",
    "        return (row['fullTimeWorkers'] * labor_cost_dict[row['Center']] + row['partTimeWorkers'] * 1.15 * labor_cost_dict[row['Center']])\n",
    "    \n",
    "    labor_cost['Cost'] = labor_cost.apply(calculate_cost, axis=1)\n",
    "    labor_cost['Cost Description'] = labor_cost['Center'] + ' Labor Costs'\n",
    "    \n",
    "    active_cells_df['fullTimeWorkers'] = labor_cost['fullTimeWorkers']\n",
    "    active_cells_df['partTimeWorkers'] = labor_cost['partTimeWorkers']\n",
    "\n",
    "    labor_summary = labor_cost.copy()\n",
    "    labor_summary['Date'] = pd.to_datetime(labor_summary['Date'])\n",
    "    labor_summary['Date'] = labor_summary['Date'].dt.year\n",
    "    labor_summary = labor_summary.groupby(['Date', 'Cost Description']).agg({'Cost': 'sum'}).reset_index()\n",
    "\n",
    "    return labor_cost[['Date', 'Cost Description', 'Cost']], active_cells_df, labor_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cost_summary(df):\n",
    "    # Split 'Cost Description' into 'Center' and 'Cost Type'\n",
    "    df['Center'] = df['Cost Description'].str.split(' ').str[0]\n",
    "    df['Cost Type'] = df['Cost Description'].str.split(' ').str[1]\n",
    "    \n",
    "    # Pivot with 'Date' as the index, 'Center' as columns, and 'Cost' as values\n",
    "    pivoted_df = df.pivot(index=['Date', 'Cost Type'], columns='Center', values='Cost')\n",
    "\n",
    "    # Reset index to turn 'Date' and 'Cost Type' back into columns\n",
    "    pivoted_df.reset_index(inplace=True)\n",
    "    \n",
    "    # Rename columns for clarity\n",
    "    pivoted_df.columns.name = None\n",
    "\n",
    "    return pivoted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_service_level_plan(s, production_demand, production_capacity, production_costs):\n",
    "    yearly_cell_df = find_cells_over_time(production_demand, production_capacity, s)\n",
    "    active_cells_df = create_active_cells_plan(production_capacity, production_demand)\n",
    "    active_cells_df = process_daily_table(production_capacity, production_demand, s)\n",
    "    cell_setup_costs = calculate_setup_costs(yearly_cell_df)\n",
    "    cell_operating_costs, operating_summary = calculate_cell_operating_costs(active_cells_df)\n",
    "    labor_costs, active_cells_df, labor_summary = calculate_labor_costs(active_cells_df)\n",
    "    cost_summary = pd.concat([cell_setup_costs.drop(columns='Cumulative Cost'), operating_summary, labor_summary], axis=0)\n",
    "    cost_summary = create_cost_summary(cost_summary)\n",
    "    \n",
    "    # Create dictionary of raw data tables to return\n",
    "    raw_data = {\n",
    "        'cell_setup_costs': cell_setup_costs,\n",
    "        'cell_operating_costs': cell_operating_costs,\n",
    "        'labor_costs': labor_costs\n",
    "    }\n",
    "    \n",
    "    return active_cells_df, yearly_cell_df, raw_data, cost_summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Date       Cost Description     Cost  Additional Cost  Cumulative Cost\n",
      "5   2020  Bottling Set-Up Costs   8000.0           8000.0           8000.0\n",
      "6   2021  Bottling Set-Up Costs      0.0              0.0           8000.0\n",
      "7   2022  Bottling Set-Up Costs   8000.0           8000.0          16000.0\n",
      "8   2023  Bottling Set-Up Costs   8000.0           8000.0          24000.0\n",
      "9   2024  Bottling Set-Up Costs -16000.0         -16000.0           8000.0\n",
      "0   2020    Mixing Set-Up Costs  15000.0          15000.0          15000.0\n",
      "1   2021    Mixing Set-Up Costs  15000.0          15000.0          30000.0\n",
      "2   2022    Mixing Set-Up Costs  30000.0          30000.0          60000.0\n",
      "3   2023    Mixing Set-Up Costs  30000.0          30000.0          90000.0\n",
      "4   2024    Mixing Set-Up Costs -75000.0         -75000.0          15000.0\n",
      "10  2020   Packing Set-Up Costs   5000.0           5000.0           5000.0\n",
      "11  2021   Packing Set-Up Costs   5000.0           5000.0          10000.0\n",
      "12  2022   Packing Set-Up Costs  15000.0          15000.0          25000.0\n",
      "13  2023   Packing Set-Up Costs  10000.0          10000.0          35000.0\n",
      "14  2024   Packing Set-Up Costs -30000.0         -30000.0           5000.0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Cost Description</th>\n",
       "      <th>Cost</th>\n",
       "      <th>Additional Cost</th>\n",
       "      <th>Cumulative Cost</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2020</td>\n",
       "      <td>Bottling Set-Up Costs</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>8000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2021</td>\n",
       "      <td>Bottling Set-Up Costs</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2022</td>\n",
       "      <td>Bottling Set-Up Costs</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>16000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2023</td>\n",
       "      <td>Bottling Set-Up Costs</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>8000.0</td>\n",
       "      <td>24000.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2024</td>\n",
       "      <td>Bottling Set-Up Costs</td>\n",
       "      <td>-16000.0</td>\n",
       "      <td>-16000.0</td>\n",
       "      <td>8000.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Date       Cost Description     Cost  Additional Cost  Cumulative Cost\n",
       "5  2020  Bottling Set-Up Costs   8000.0           8000.0           8000.0\n",
       "6  2021  Bottling Set-Up Costs      0.0              0.0           8000.0\n",
       "7  2022  Bottling Set-Up Costs   8000.0           8000.0          16000.0\n",
       "8  2023  Bottling Set-Up Costs   8000.0           8000.0          24000.0\n",
       "9  2024  Bottling Set-Up Costs -16000.0         -16000.0           8000.0"
      ]
     },
     "execution_count": 493,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_cells_plan, yearly_cell_plan, raw_tables, total_costs = create_service_level_plan(5, production_demand, production_capacity, production_costs)\n",
    "raw_tables['cell_setup_costs'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dashboard"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data-science",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
